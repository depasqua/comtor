\begin{abstract}
The grading or assessment of source code comments is an imprecise,
labor-intensive procedure at best.  Conventions for documenting at the
source level vary between languages and working environments. Because
of this lack of standards, it is hard to empirically measure the
``quality'' of a comment, and therefore difficult to objectively
measure comment quality over time or in relation to the developing
code base.

Comment Mentor (CoMtor) is an educational tool to assist educators,
seasoned developers, and new programmers learn better strategies for
source code-level documentation by formalizing and automating the
``grading'' process. It is of direct assistence in a practical setting
as well as the classroom: developers can make sure comments are at
some threshold level of quality before code is committed to the
repository. We describe the design and implementation of CoMtor and
report on its use in assessing several code bases, ranging from 
student code to large open source projects.
\end{abstract}
